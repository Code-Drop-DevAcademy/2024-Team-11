//
//  AllNews.swift
//  Code Drop_Team 11
//
//  Created by 김이예은 on 6/15/24.
//

import Foundation

var AllNews: [News] = [
    News(title: "웹 3.0 생태계를 빠르게 꽃 피우는 법", text: "Blockchain as a Service(이하 BaaS)는 제 3자가 Blockchain을 플랫폼으로 활용해서 다양한 응용기능이나 서비스를 제공하는 웹 3.0 분야입니다. 'as a Service' 모델은 기업과 개인이 서비스를 직접 소유하거나, 그에 준하는 권리를 보유하지 않아도 관련 서비스를 사용할 수 있게 함으로써 서비스에 대한 효율성과 접근성을 크게 향상시킵니다.", link: "https://techtopic.skplanet.com/baas/?ref=codenary"),
    News(title: "iOS 멀티 프레임워크 환경에서 리소스 효율적으로 관리하기", text: "현재 카카오페이를 포함한 많은 회사에서 빌드 속도, 생산성 등 다양한 이유로 프로젝트를 멀티 모듈로 구성해서 앱을 개발하고 있는데요. 많은 모듈이 있는 큰 프로젝트를 운영하다 보면 여러 가지 문제를 마주합니다. 최근 카카오페이에서도 이러한 멀티 모듈 환경에서 늘어나는 앱 용량을 어떻게 관리할지 고민했습니다. 앱 용량에 영향을 끼치는 여러 요소가 있지만, 그중 리소스(이미지, 애니메이션, 컬러 등)는 앱 용량에 직접적인 영향을 주는데요. 많은 개발자들이 한 프로젝트에서 작업하는 만큼 그에 따라 리소스도 많이 추가하다보니 앱 용량이 점점 커졌습니다. 관리가 필요하다는 걸 더욱 느꼈습니다.", link: "https://tech.kakaopay.com/post/ios-manage-resources-in-multi-framework/?ref=codenary"),
    News(title: "질문에 대처하는 어느 플랫폼 개발자의 이야기", text: "플랫폼 프로젝트는 성장 과정에서 필연적으로 여러 번 확장합니다. 이에 따라 단기적인 성과를 달성하는 것을 넘어 지속적으로 발전하며 확장하기 위한 도전 과제에 끊임없이 직면합니다. 주어진 현실에 안주하지 않고 지속적으로 성장의 의미를 찾아야 하는 이유입니다. \nMessagingHub도 그와 같은 과정을 거쳐오고 있습니다. 최초에 폴링(polling) 이슈를 해결하기 위해 시작해서 이후 앱 푸시와 이메일, 문자, 이제는 채팅에 이르기까지 그 기능을 지속적으로 확장해 왔습니다. 이에 따라 서비스나 컴포넌트와의 접점도 점차 넓어지고 있습니다.\n그런데 한 사람이 감당할 수 있는 업무량에는 분명한 한계가 있습니다. 해야 할 일은 많고 커뮤니케이션 비용은 높아지는데 인력이 부족하다면 업무 진행 과정에서 반드시 병목 지점이 발생합니다. 프로젝트의 지속 가능한 운영과 성장을 위한 중요한 기로에 서 있는 이 상황은 어렵고 힘들긴 하지만 한편으론 흥미로운 도전 과제이기도 합니다.\n이 상황을 짧게 정리하면 이렇습니다.\n플랫폼 프로젝트로서 초기 성장 단계를 성공적으로 넘어섰습니다.\n그러나 업무 범위가 확장된 것에 비해 실무 담당자의 수는 매우 부족합니다.따라서 지속 가능한 업무 환경을 만들기 위한 돌파구가 필요한 중요한 시점입니다.", link: "https://techblog.lycorp.co.jp/ko/how-platform-developers-handle-questions?ref=codenary"),
    News(title: "애플, AI 예측 코드 완성 기능 탑재한 Xcode 16 베타 버전 출시!", text: "Apple이 Xcode 16 베타 버전을 출시했습니다. 이 업데이트는 AI 기반의 예측 코드 완성 기능을 특징으로 하며, Swift 언어와 예정된 Swift 6 언어 릴리스에 대한 지원도 강조됩니다. Xcode 16 베타는 6월 10일 Apple Developer 웹사이트에서 제공되기 시작했습니다. 예측 코드 완성 기능은 Swift와 Apple SDK를 위해 특별히 훈련된 머신 러닝 모델에 의해 구동됩니다.\nSwift 언어의 경우, 빌드 시스템은 Clang 및 Swift 컴파일러와 협력하여 프로젝트 소스의 모듈 종속성을 명시적 작업 집합으로 발견하고 빌드합니다. 명시적으로 빌드된 모듈은 디버거 성능을 향상시키고, 빌드 시스템이 병렬성을 최대화하기 위해 더 나은 스케줄링 결정을 내릴 수 있게 합니다. 또한, Swift 6 언어 모드는 'self•conforming' 타입을 사용하여 제네릭 함수에 전달되는 존재적 값을 엽니다. 프로젝트는 새로운 빌드 설정을 통해 개별적으로 Swift 6 기능을 선택하여 마이그레이션할 수 있습니다.\nXcode 16 베타에는 iOS 18, macOS Sequoia 15, iPadOS 18, tvOS 18, watchOS 11, 및 visionOS 2용 SDK가 포함되어 있습니다. 새로운 기능으로는 xconfig 파일 구문을 사용하는 빌드 설정 편집기의 복사 및 붙여넣기 기능, 파일 유형별 기본 편집기를 선택할 수 있는 Project Navigator의 'Open As' 컨텍스트 메뉴 지원 등이 있습니다. 또한, C++ 표준 라이브러리 강화 기능, 디버그 바의 현재 백트레이스 보기 제어, 다양한 프로젝트와 구성을 지원하는 새로운 프리뷰 실행 엔진, 새로운 파일 생성 워크플로우, 그리고 의미적 검색을 지원하는 Quick Actions 기능이 추가되었습니다.", link: "https://www.apple.com/kr/newsroom/2024/06/apple-empowers-developers-and-fuels-innovation-with-new-tools-and-resources/"),
    News(title: "OpenAI, 'ChatGPT' 음성읽기 기능 추가... 요리 재료를 대신 읽어준다", text: "OpenAI는 지난 3월 5일, ChatGPT가 이제 사용자의 응답을 읽어주는 기능을 추가했다고 발표했습니다. 이를 통해 사용자는 핸즈프리 경험을 누릴 수 있게 되었습니다. iOS와 Android에서는 ChatGPT의 응답을 탭하고 잡아당기면 'Read Aloud'라는 옵션이 나타나며, 웹에서는 메시지 아래에 새로 생긴 스피커 아이콘을 탭하여 이 기능에 접근할 수 있습니다. 사용자는 특정 대화에서 모든 미래의 메시지를 자동으로 읽어주도록 설정할 수 있으며, 일시정지, 빨리감기, 되감기를 요청하거나 선호하는 독자의 목소리를 변경할 수도 있습니다. 이 기능은 현재 iOS와 Android에서 사용 가능하며, 웹에서도 출시가 시작되었습니다. 또한, OpenAI는 음성을 텍스트로 변환하는 아이콘을 마이크로 업데이트하여 사용자가 그 옵션을 더 쉽게 찾을 수 있도록 했습니다.", link: "https://www.digitaltoday.co.kr/news/articleView.html?idxno=508220"),
    News(title: "int는 몇 바이트 인가요?", text: "사실 Python의 경우 int의 크기는 정해져 있지 않습니다. 기본적으로 정해진 값(4 또는 8byte)를 넘어가더라도 자동으로 데이터 값을 증가시켜주기 때문입니다. sys.maxsize가 8byte가 나온 이유는 64bit컴퓨터였기 때문이고 즉, 컴퓨터의 연산 처리량에 맞추어 값이 변한다고 볼 수 있습니다. 혹시 미래에 128bit 컴퓨터가 나온다면 Python의 sys.maxsize는 16byte로 나올 것입니다.\n플랫폼에 독립적이냐, 의존적이냐의 차이도 발생합니다. 기본적으로 C, C++의 경우엔 플랫폼에 의존적인 언어 입니다. Unix나 Linux, Windows의 경우도 C로 짜여진 커널을 사용하고 있기 때문에 컴파일러의 경우 두 플랫폼 모두 지원하지만 내부 커널의 데이터 처리 방식도 다르고 그로 인해 데이터 모델의 차이가 발생합니다. 그 부분이 64bit로 변화하면서 Unix, Linux는 LP64모델을 Windows는 LLP64모델을 지원하게 되었습니다. 컴파일러는 플랫폼에서 정의한 데이터 모델대로 구현되어 있고, 따라서 데이터 모델 역시 플랫폼에 의존적일 수 밖에 없습니다. 물론 데이터 모델 뿐만 아니라 컴파일러를 통해 만들어진 바이너리를 동작 시키기 위한 부분 역시 플랫폼 종속적입니다. 반면 플랫폼에 독립적인 언어들, 인터프리터 언어인 Python이나 각 플랫폼 위에서 독립적인 가상머신(JVM)을 제공하여 어떤 플랫폼에서도 동일한 코드로 동일한 바이너리를 만들어낼 수 있는 Java의 경우엔 플랫폼과 상관없이 늘 동일한 값을 보장해 줍니다.\n위의 예제에서 Java의 경우 int가 4byte가 나왔고, 그렇다면 64bit 데이터 모델이 ILP64인 플랫폼에서는 8byte가 나올 것 같지만 Java의 JVM에서 int는 4byte로 정의해 놓았기 때문에 ILP64 모델에서도 Java는 여전히 4byte로 나오게 될 것 입니다. 마찬가지로 Python 역시 동일한 값을 출력할 것입니다. 하지만 C나 C++의 경우엔 ILP64 모델의 플랫폼에선 8byte로 출력 될 것입니다.", link: "https://devocean.sk.com/blog/techBoardDetail.do?ID=164788&ref=codenary"),
    News(title: "AI를 활용한 손쉬운 음성 테스트 데이터 생성", text: "Python과 gTTS(Google Text-to-Speech) 라이브러리를 사용해 텍스트를 음성으로 변환하고 MP3 파일로 저장하는 방법을 소개합니다. 이 과정은 텍스트를 입력하여 음성 파일을 만들고, 필요 시 'playsound' 모듈을 이용해 직접 재생할 수 있습니다. 또한, OpenAI API를 활용해 특정 내용의 스크립트를 자동 생성한 후 이를 음성 파일로 변환하는 고급 사용 예도 제공됩니다.", link: "https://devocean.sk.com/blog/techBoardDetail.do?ID=165825&boardType=techBlog&searchData=&page=&subIndex=최신+기술+블로그&ref=codenary"),
    News(title: "고성능 ML 백엔드를 위한 10가지 Python 성능 최적화 팁", text: "Python은 배우기 쉽고, ML 관련 라이브러리를 포함한 오픈소스 생태계가 상당히 발전해있는 좋은 언어입니다. 편의성이 좋다 보니 여러 회사들이 데이터 분석과 ML 모델 학습뿐만 아니라, 백엔드 서버에서도 Python을 자주 사용합니다. (대표적으로 Instagram도 백엔드 서버로 Python을 사용합니다 [0-1]). 하이퍼커넥트의 많은 ML 백엔드 서버들도 Python으로 작성되고 있는데요, 하지만 Python은 실행 속도가 느리다는 치명적인 단점이 있습니다. Python은 분명 ML 도메인에서 사용하기 좋은 언어이긴 하지만, 응답시간이 중요한 로직에서도 Python 백엔드 서버를 운영하면서 Python의 느린 속도 때문에 많은 고통을 겪어 왔습니다.\nPython의 속도가 문제가 되어도, 이미 작성된 로직들을 C++, Go, Rust, Kotlin과 같은 더 빠른 언어로 포팅하기는 쉽지 않습니다. 기본적으로 전체 비즈니스 로직을 새로운 언어로 다시 작성하는 것은 시간이 매우 많이 들며, 또 Numpy나 PyTorch와 같은 라이브러리의 이점을 포기하기도 쉽지 않기 때문이죠. 하이퍼커넥트도 Python에서 다른 언어로 포팅하기 어려운 상황들을 많이 겪어왔고, 그때마다 Python 자체를 최대한 빠르게 사용하기 위한 다양한 트릭들을 발견하며 성능 요구사항을 맞춰왔습니다.\n이번 포스트에서는 하이퍼커넥트가 Python으로 작성된 다양한 ML 백엔드 서버들을 운영하며 발견한 성능 최적화 기법 10가지를 공유해 보려 합니다. 특히 다량의 데이터를 사용하는 ML 워크로드에 특화된 최적화 기법들을 다루며, ML 백엔드에서 자주 사용되는 third-party 라이브러리를 효과적으로 사용하는 방법도 같이 공유합니다. Pypy, Numba, C binding 처럼 팀의 반발을 살 수 있으며(?), 유지보수성 난이도가 높아져서 적용이 어려운 방법들은 이번 포스트에선 다루지 않습니다. 단 몇 줄의 코드 수정만으로 서버의 응답시간(latency)을 절반 이상 낮출 수 있는 팁들도 있으니, 재미있게 읽어주세요.", link: "https://hyperconnect.github.io/2023/05/30/Python-Performance-Tips.html?ref=codenary"),
    News(title: "파이썬을 처음 사용하는 동료와 효율적으로 일하는 방법", text: "당근마켓에서 여러 팀과 협업하다 보면 신경 써야 할 부분들이 매우 많아요. 단순히 소스 코드를 통해 기능을 만들어내는 것 이상으로, 어떻게 하면 지속적으로 성장하는 소프트웨어를 만들어 낼 수 있는지 함께 고민해야 하는 순간들이 많거든요.\n당근마켓에서는 보통 코드 리뷰를 통해 서로 작성한 소스 코드에 대해 피드백을 주고받으며 개선하는데요. 그렇다면 어떻게 해야 서로 피드백을 잘 주고받을 수 있을까요?\n오늘은 여러 언어와 기술을 사용하는 당근마켓에서 코드 리뷰를 진행하기 전에 어떤 고민을 했고 또 어떻게 해결했는지 얘기해보려 해요.\n\n고민할 거리를 줄여 주는 규칙의 효용성 \n여러분은 어느 출판사의 편집자이고 두 명의 작가가 함께 한 편의 에세이를 연재하는 상황이라 가정해볼까요? A라는 작가는 짧은 호흡의 글을 쓰고 종결어미를 현재 읽고 계신 글처럼 해요체로 끝내기를 좋아해요. 다른 B라는 작가는 반대로 긴 호흡의 글을 쓰며 친근한 느낌을 주고 싶어 평어체를 쓰는 걸 좋아해요. 둘의 글을 인터넷에 발행하기 위해 받아 본 결과 아래와 같았어요.", link: "https://medium.com/daangn/파이썬을-처음-사용하는-동료와-효율적으로-일하는-방법-bb52c3a433fa")
]
